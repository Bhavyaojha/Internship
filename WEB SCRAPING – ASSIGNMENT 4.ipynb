{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70692755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUES NO 1\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c4a0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20739707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[24]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[25]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[36]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Dark Horse\"[38]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Girls Like You\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Mi Gente\"[48]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.   \"Masha and the Bear – Recipe for Disaster\"[24]   \n",
       "10  11.                              \"Gangnam Style\"[25]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                          \"Thinking Out Loud\"[36]   \n",
       "18  19.                                     \"Axel F\"[37]   \n",
       "19  20.                                 \"Dark Horse\"[38]   \n",
       "20  21.                             \"Girls Like You\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                        \"Baa Baa Black Sheep\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                                    \"Perfect\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.                                   \"Mi Gente\"[48]   \n",
       "\n",
       "                                         Artist        Upload_date  Views  \n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.05  \n",
       "1                                    Luis Fonsi   January 12, 2017   7.93  \n",
       "2                                   LooLoo Kids    October 8, 2016   6.40  \n",
       "3                                    Ed Sheeran   January 30, 2017   5.77  \n",
       "4                                   Wiz Khalifa      April 6, 2015   5.59  \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   5.54  \n",
       "6                                     ChuChu TV      March 6, 2014   4.77  \n",
       "7                                   Mark Ronson  November 19, 2014   4.65  \n",
       "8                                   Miroshka TV  February 27, 2018   4.60  \n",
       "9                                    Get Movies   January 31, 2012   4.50  \n",
       "10                                          Psy      July 15, 2012   4.50  \n",
       "11                   Cocomelon – Nursery Rhymes       May 24, 2018   4.24  \n",
       "12                                    El Chombo      April 5, 2018   4.00  \n",
       "13                                     Maroon 5   January 14, 2015   3.74  \n",
       "14                                   Katy Perry  September 5, 2013   3.63  \n",
       "15                                  OneRepublic       May 31, 2013   3.62  \n",
       "16                                Justin Bieber   October 22, 2015   3.57  \n",
       "17                                   Ed Sheeran    October 7, 2014   3.48  \n",
       "18                                   Crazy Frog      June 16, 2009   3.45  \n",
       "19                                   Katy Perry  February 20, 2014   3.32  \n",
       "20                                     Maroon 5       May 31, 2018   3.32  \n",
       "21                                  Alan Walker   December 3, 2015   3.32  \n",
       "22                   Cocomelon – Nursery Rhymes      June 25, 2018   3.31  \n",
       "23                                    Passenger      July 25, 2012   3.27  \n",
       "24                             Enrique Iglesias     April 11, 2014   3.25  \n",
       "25                                  Major Lazer     March 22, 2015   3.24  \n",
       "26                                   Ed Sheeran   November 9, 2017   3.22  \n",
       "27                                      Shakira       June 4, 2010   3.21  \n",
       "28                                 Taylor Swift    August 18, 2014   3.19  \n",
       "29                                     J Balvin      June 29, 2017   3.11  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating blank list\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "#Scraping Rank\n",
    "rank=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "\n",
    "#Scraping Name\n",
    "name=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Artist\n",
    "artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Views\n",
    "views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "for i in views:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Upload_date\n",
    "upload_date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "for i in upload_date:\n",
    "    Upload_date.append(i.text)\n",
    "    \n",
    "Youtube_viewed=pd.DataFrame({})\n",
    "Youtube_viewed['Rank']=Rank\n",
    "Youtube_viewed['Name']=Name\n",
    "Youtube_viewed['Artist']=Artist\n",
    "Youtube_viewed['Upload_date']=Upload_date\n",
    "Youtube_viewed['Views']=Views\n",
    "Youtube_viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1772aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUES NO 02 \n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76dd7353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE ODI SERIES 2022</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>1st ODI - Harare Sports Club, Harare</td>\n",
       "      <td>18 AUG 2022\\n12:45 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Match_title               Series  \\\n",
       "0  INDIA TOUR OF ZIMBABWE ODI SERIES 2022  Harare Sports Club,   \n",
       "\n",
       "                                  Place                       Date  \n",
       "0  1st ODI - Harare Sports Club, Harare  18 AUG 2022\\n12:45 PM IST  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Empty list\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "#Scraping Match_title\n",
    "match_title= driver.find_elements(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[1]/h5[2]/span\")\n",
    "for i in match_title:\n",
    "    Match_title.append(i.text)\n",
    "    \n",
    "#Scraping Series\n",
    "series= driver.find_elements(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[4]/div/span[2]\")\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "    \n",
    "#Scraping Place\n",
    "place= driver.find_elements(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[4]/div\")\n",
    "for i in place:\n",
    "    Place.append(i.text)   \n",
    "    \n",
    "#Scraping Date\n",
    "date= driver.find_elements(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div[1]/div/div[1]/div\")\n",
    "for i in date:\n",
    "    Date.append(i.text)   \n",
    "    \n",
    "\n",
    "\n",
    "Fixture=pd.DataFrame({})\n",
    "Fixture['Match_title']=Match_title\n",
    "Fixture['Series']=Series\n",
    "Fixture['Place']=Place\n",
    "Fixture['Date']=Date\n",
    "Fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fca2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUES NO 4\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import re\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9369680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAVYA OJHA\\AppData\\Local\\Temp\\ipykernel_16836\\2848808550.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "driver.maximize_window()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06432869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Click Economy\n",
    "Economy=driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "Economy.click()\n",
    "\n",
    "#Click India\n",
    "India= driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/div/a[3]\")\n",
    "India.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de387958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_at_current_price_19_20</th>\n",
       "      <th>GSDP_at_current_price_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_at_current_price_19_20  \\\n",
       "0     1                Maharashtra                           -   \n",
       "1     2                 Tamil Nadu                   1,845,853   \n",
       "2     3              Uttar Pradesh                   1,687,818   \n",
       "3     4                    Gujarat                           -   \n",
       "4     5                  Karnataka                   1,631,977   \n",
       "5     6                West Bengal                   1,253,832   \n",
       "6     7                  Rajasthan                   1,020,989   \n",
       "7     8             Andhra Pradesh                     972,782   \n",
       "8     9                  Telangana                     969,604   \n",
       "9    10             Madhya Pradesh                     906,672   \n",
       "10   11                     Kerala                           -   \n",
       "11   12                      Delhi                     856,112   \n",
       "12   13                    Haryana                     831,610   \n",
       "13   14                      Bihar                     611,804   \n",
       "14   15                     Punjab                     574,760   \n",
       "15   16                     Odisha                     521,275   \n",
       "16   17                      Assam                           -   \n",
       "17   18               Chhattisgarh                     329,180   \n",
       "18   19                  Jharkhand                     328,598   \n",
       "19   20                Uttarakhand                           -   \n",
       "20   21            Jammu & Kashmir                           -   \n",
       "21   22           Himachal Pradesh                     165,472   \n",
       "22   23                        Goa                      80,449   \n",
       "23   24                    Tripura                      55,984   \n",
       "24   25                 Chandigarh                           -   \n",
       "25   26                 Puducherry                      38,253   \n",
       "26   27                  Meghalaya                      36,572   \n",
       "27   28                     Sikkim                      32,496   \n",
       "28   29                    Manipur                      31,790   \n",
       "29   30                   Nagaland                           -   \n",
       "30   31          Arunachal Pradesh                           -   \n",
       "31   32                    Mizoram                      26,503   \n",
       "32   33  Andaman & Nicobar Islands                           -   \n",
       "\n",
       "   GSDP_at_current_price_18_19 Share_18_19 GDP_billion  \n",
       "0                    2,632,792      13.94%     399.921  \n",
       "1                    1,630,208       8.63%     247.629  \n",
       "2                    1,584,764       8.39%     240.726  \n",
       "3                    1,502,899       7.96%     228.290  \n",
       "4                    1,493,127       7.91%     226.806  \n",
       "5                    1,089,898       5.77%     165.556  \n",
       "6                      942,586       4.99%     143.179  \n",
       "7                      862,957       4.57%     131.083  \n",
       "8                      861,031       4.56%     130.791  \n",
       "9                      809,592       4.29%     122.977  \n",
       "10                     781,653       4.14%     118.733  \n",
       "11                     774,870       4.10%     117.703  \n",
       "12                     734,163       3.89%     111.519  \n",
       "13                     530,363       2.81%      80.562  \n",
       "14                     526,376       2.79%      79.957  \n",
       "15                     487,805       2.58%      74.098  \n",
       "16                     315,881       1.67%      47.982  \n",
       "17                     304,063       1.61%      46.187  \n",
       "18                     297,204       1.57%      45.145  \n",
       "19                     245,895       1.30%      37.351  \n",
       "20                     155,956       0.83%      23.690  \n",
       "21                     153,845       0.81%      23.369  \n",
       "22                      73,170       0.39%      11.115  \n",
       "23                      49,845       0.26%       7.571  \n",
       "24                      42,114       0.22%       6.397  \n",
       "25                      34,433       0.18%       5.230  \n",
       "26                      33,481       0.18%       5.086  \n",
       "27                      28,723       0.15%       4.363  \n",
       "28                      27,870       0.15%       4.233  \n",
       "29                      27,283       0.14%       4.144  \n",
       "30                      24,603       0.13%       3.737  \n",
       "31                      22,287       0.12%       3.385  \n",
       "32                           -           -           -  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating empty list\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_at_current_price_19_20=[]\n",
    "GSDP_at_current_price_18_19=[]\n",
    "Share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "#Scraping Rank\n",
    "rank= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    if i.text is None:\n",
    "        Rank.append('--')\n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "        \n",
    "#Scraping State\n",
    "state= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "for i in state:\n",
    "    if i.text is None:\n",
    "        State.append('--')\n",
    "    else:\n",
    "        State.append(i.text)\n",
    "                \n",
    "#Scraping GSDP_at_current_price_19_20\n",
    "gSDP_at_current_price_19_20= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "for i in gSDP_at_current_price_19_20:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_19_20.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_19_20.append(i.text)\n",
    "        \n",
    "#Scraping GSDP_at_current_price_18_19\n",
    "gSDP_at_current_price_18_19= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "for i in gSDP_at_current_price_18_19:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_18_19.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_18_19.append(i.text)\n",
    "        \n",
    "#Scraping Share_18_19\n",
    "share_18_19= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "for i in share_18_19:\n",
    "    if i.text is None:\n",
    "        Share_18_19.append('--')\n",
    "    else:\n",
    "        Share_18_19.append(i.text)\n",
    "        \n",
    "#Scraping GDP_billion\n",
    "gDP_billion= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "for i in gDP_billion:\n",
    "    if i.text is None:\n",
    "        GDP_billion.append('--')\n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "        \n",
    "# creating dataframe\n",
    "GDP_India=pd.DataFrame({})\n",
    "GDP_India['Rank']=Rank\n",
    "GDP_India['State']=State\n",
    "GDP_India['GSDP_at_current_price_19_20']=GSDP_at_current_price_19_20\n",
    "GDP_India['GSDP_at_current_price_18_19']=GSDP_at_current_price_18_19\n",
    "GDP_India['Share_18_19']=Share_18_19\n",
    "GDP_India['GDP_billion']=GDP_billion\n",
    "GDP_India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "842bffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAVYA OJHA\\AppData\\Local\\Temp\\ipykernel_16836\\3951893907.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#QUES NO 7\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/recruiters/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04333a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"//input[@class='sugInp']\")\n",
    "search.send_keys('Data Science')\n",
    "\n",
    "search_btn=driver.find_element(By.XPATH,\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3df3c508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skills_they_hire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Data Science, Python, Data Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Ethical Hacking, Security Operations Center, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                             Vaishnavi Kudalkar   \n",
       "11                                 Priyanka Akiri   \n",
       "12                                Kalpana Dumpala   \n",
       "13                                        Mubarak   \n",
       "14                                 Kushal Rastogi   \n",
       "15                             Mahesh Babu Channa   \n",
       "16                                   Kapil Devang   \n",
       "17                                Sakshi Chhikara   \n",
       "18                                    Ruchi Dhote   \n",
       "19                                  Manisha Yadav   \n",
       "20                                    Riya Rajesh   \n",
       "21                           Rashmi Bhattacharjee   \n",
       "22                                  Faizan Kareem   \n",
       "23                                 Rithika dadwal   \n",
       "24                             Sandhya Khandagale   \n",
       "25                                      Shaun Rao   \n",
       "26                                  Azahar Shaikh   \n",
       "27                                          Manas   \n",
       "28                                          kumar   \n",
       "29                                   Sunil Vedula   \n",
       "30                                    Rajat Kumar   \n",
       "31                                Dhruv Dev Dubey   \n",
       "32                                      Jayanth N   \n",
       "33                                         Avodha   \n",
       "34                                    Priya Khare   \n",
       "35                                    Amit Sharma   \n",
       "36                                          Kanan   \n",
       "37                           Shashikant Chaudhary   \n",
       "38                                           Brad   \n",
       "39                                   Rutuja Pawar   \n",
       "40                            Madhusudhan Sridhar   \n",
       "41                                    Ankit Sinha   \n",
       "42                                 Gaurav Chouhan   \n",
       "43                                   Rashi Kacker   \n",
       "44                                        Ashwini   \n",
       "45                                   Balaji Kolli   \n",
       "46                                 Rajani Nagaraj   \n",
       "47                                    ROHIT Kumar   \n",
       "48                                 Amir Chowdhury   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                         HR Executive   \n",
       "11                           HR Manager   \n",
       "12                     Executive Hiring   \n",
       "13                           Company HR   \n",
       "14                           Company HR   \n",
       "15                         HR Team Lead   \n",
       "16                           HR Manager   \n",
       "17                 Assistant Manager HR   \n",
       "18  Senior Executive Talent Acquisition   \n",
       "19                         HR Executive   \n",
       "20           Manager Talent Acquisition   \n",
       "21                              HR Head   \n",
       "22                           HR MANAGER   \n",
       "23                         HR Recruiter   \n",
       "24                         HR Recruiter   \n",
       "25              Manager Human Resources   \n",
       "26                    Company Recruiter   \n",
       "27              Lead Talent acquisition   \n",
       "28                           Proprietor   \n",
       "29                                  CEO   \n",
       "30                          Founder CEO   \n",
       "31             Company Recruitment Head   \n",
       "32                      Project Manager   \n",
       "33       Business Development Associate   \n",
       "34                       Senior Manager   \n",
       "35                           Consultant   \n",
       "36         senior technology instructor   \n",
       "37             HR Recruiter/HR Excutive   \n",
       "38        Manager, Technical Recruiting   \n",
       "39                  Technical Recruiter   \n",
       "40                      Erp Implementer   \n",
       "41                       Head Analytics   \n",
       "42              Chief Technical Officer   \n",
       "43                   Sr Product Manager   \n",
       "44             Director Global Delivery   \n",
       "45                           Co Founder   \n",
       "46                           HR Manager   \n",
       "47                            Architect   \n",
       "48                     Managing Partner   \n",
       "\n",
       "                                     Skills_they_hire  \n",
       "0   Classic ASP Developer, Internet Marketing Prof...  \n",
       "1   .Net, Java, Data Science, Linux Administration...  \n",
       "2   Data Science, Artificial Intelligence, Machine...  \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5   Analytics, Business Intelligence, Business Ana...  \n",
       "6                                        Data Science  \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8   Technical Training, Software Development, Pres...  \n",
       "9   Software Development, It Sales, Account Manage...  \n",
       "10               Data Science, Python, Data Analytics  \n",
       "11  Oracle Dba, Data Science, Data Warehousing, ET...  \n",
       "12  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
       "13  Business Intelligence, Data Warehousing, Data ...  \n",
       "14  Office Administration, Hr Administration, tele...  \n",
       "15  Social Media, digital media maketing, seo, smm...  \n",
       "16     Big Data, Hadoop, Data Analytics, Data Science  \n",
       "17  React.js, Data Science, Java, Front End, Busin...  \n",
       "18  Qlikview, Qlik Sense, Microsoft Azure, Power B...  \n",
       "19  Telecalling, Client Interaction, Marketing, Re...  \n",
       "20                                       Data Science  \n",
       "21  Corporate Sales, Software Development, Softwar...  \n",
       "22  Data Analytics, Data Science, Machine Learning...  \n",
       "23  Data Science, Machine Learning, Python, R, Dee...  \n",
       "24  Big Data, Data Science, Artificial Intelligenc...  \n",
       "25  Java, Net, Angularjs, Hr, Infrastructure, Mana...  \n",
       "26  Data Science, Artificial Intelligence, Machine...  \n",
       "27  Software Architecture, Vp Engineering, Product...  \n",
       "28  Data Science, Hadoop, Rpas, Devops, Python, Aw...  \n",
       "29  Signal Processing, Machine Learning, Neural Ne...  \n",
       "30  Web Technologies, Project Management, Software...  \n",
       "31  Server Administartion, Verilog, Vhdl, Digital ...  \n",
       "32  Data Analytics, Managed Services, Team Leading...  \n",
       "33  Ethical Hacking, Security Operations Center, S...  \n",
       "34  Data Science, Artificial Intelligence, analyti...  \n",
       "35  Machine Learning, Artificial Intelligence, Dat...  \n",
       "36  C, C++, Artificial Intelligence, Python, Php, ...  \n",
       "37  Relationship Management, Retail Sales, Private...  \n",
       "38                 Data Science, Software Engineering  \n",
       "39  Data Science, Big Data Analytics, Digital Mark...  \n",
       "40                  Data Science, Recruitment, Salary  \n",
       "41  B.Tech, Tableau, Statistics, R, Analytics, Tim...  \n",
       "42  Software Development, Business Intelligence, B...  \n",
       "43                   Data Science, Node.js, Angularjs  \n",
       "44  Data Science, Media Marketing, Resource Planni...  \n",
       "45  Data Analysis, Learning, Data Science, Compute...  \n",
       "46  Java, Hadoop, R, Machine Learning, Spark, Flum...  \n",
       "47  Software Development, Core Java, Unit Testing,...  \n",
       "48  Machine Learning, Data Science, Product Manage...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating emepty list\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_they_hire=[]\n",
    "Location=[]\n",
    "\n",
    "\n",
    "#Scraping Name \n",
    "name=driver.find_elements(By.XPATH,\"//span[@class='fl ellipsis']\")\n",
    "for i  in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Designation \n",
    "designation=driver.find_elements(By.XPATH,\"//span[@class='ellipsis clr']\")\n",
    "for i  in designation:\n",
    "    Designation.append(i.text)    \n",
    "    \n",
    "#Scraping Company \n",
    "company=driver.find_elements(By.XPATH,\"//span[@class='highlightable']/a[2]\")\n",
    "for i  in company:\n",
    "    Company.append(i.text)   \n",
    "    \n",
    "    \n",
    "#Scraping Skills_they_hire \n",
    "skills_they_hire=driver.find_elements(By.XPATH,\"//div[@class='hireSec highlightable']\")\n",
    "for i  in skills_they_hire:\n",
    "    Skills_they_hire.append(i.text)\n",
    "    \n",
    "\n",
    "    \n",
    "#Scraping Location \n",
    "location=driver.find_elements(By.XPATH,\"//p[@class='highlightable']/span[2]\")\n",
    "for i  in location:\n",
    "    if i.text is None:\n",
    "        \n",
    "        Location.append('--')\n",
    "    else:\n",
    "        Location.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "Recruiters=pd.DataFrame({})\n",
    "Recruiters['Name']= Name[0:49]\n",
    "Recruiters['Designation']= Designation[0:49]\n",
    "Recruiters['Skills_they_hire']= Skills_they_hire[0:49]\n",
    "Recruiters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "748a70dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Ahmedabad',\n",
       " 'UK - (london)',\n",
       " 'Vadodara / Baroda',\n",
       " 'Chennai',\n",
       " 'Trivandrum',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bhopal',\n",
       " 'Chandigarh',\n",
       " 'Pune',\n",
       " 'Navi Mumbai',\n",
       " 'Cochin',\n",
       " 'Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mysoru / Mysore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'New Delhi',\n",
       " 'Chennai',\n",
       " 'Aligarh',\n",
       " 'Salt Lake City',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'MYSORE',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Ghaziabad']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5953544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAVYA OJHA\\AppData\\Local\\Temp\\ipykernel_16836\\1195056736.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QUES NO 8\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "# Scraping Book_name\n",
    "book_name=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "for i in book_name:\n",
    "    if i.text is None:\n",
    "        Book_name.append('--')\n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "        \n",
    "# Scraping Author_name\n",
    "author_name=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "for i in author_name:\n",
    "    if i.text is None:\n",
    "        Author_name.append('--')\n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "        \n",
    "# Scraping Volumes_sold\n",
    "volumes_sold=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "for i in volumes_sold:\n",
    "    if i.text is None:\n",
    "        Volumes_sold.append('--')\n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "        \n",
    "# Scraping Author_name\n",
    "publisher=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "for i in publisher:\n",
    "    if i.text is None:\n",
    "        Publisher.append('--')\n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "        \n",
    "# Scraping Genre\n",
    "genre=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in genre:\n",
    "    if i.text is None:\n",
    "        Genre.append('--')\n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "\n",
    "Top_selling_book=pd.DataFrame({})\n",
    "Top_selling_book['Book_name']=Book_name\n",
    "Top_selling_book['Author_name']=Author_name\n",
    "Top_selling_book['Volumes_sold']=Volumes_sold\n",
    "Top_selling_book['Publisher']=Publisher\n",
    "Top_selling_book['Genre']=Genre\n",
    "Top_selling_book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3335ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAVYA OJHA\\AppData\\Local\\Temp\\ipykernel_16836\\2196663909.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#QUES NO 09\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "url =\"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca611d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,021,407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,117,840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>959,788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>286,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>246,531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>193,409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40,808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>233,374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  2,021,407  \n",
       "1    51 min     8.7  1,117,840  \n",
       "2    44 min     8.2    959,788  \n",
       "3    60 min     7.5    286,923  \n",
       "4    43 min     7.6    246,531  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,268  \n",
       "96   50 min     7.8     60,161  \n",
       "97   42 min     8.1    193,409  \n",
       "98   45 min     7.1     40,808  \n",
       "99  572 min     8.6    233,374  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating empty list\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "#Scraping Name\n",
    "name=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Year_span\n",
    "year_span=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "for i in year_span:\n",
    "    Year_span.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping Genre\n",
    "genre=driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Run_time\n",
    "run_time=driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in run_time:\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping Ratings\n",
    "ratings=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-widget']/div/span[2]\")\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping Votes\n",
    "votes=driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small'][3]/span[2]\")\n",
    "for i in votes:\n",
    "    Votes.append(i.text)\n",
    "    \n",
    "Top_shows=pd.DataFrame({})\n",
    "Top_shows['Name']=Name\n",
    "Top_shows['Year_span']=Year_span\n",
    "Top_shows['Genre']=Genre\n",
    "Top_shows['Run_time']=Run_time\n",
    "Top_shows['Ratings']=Ratings\n",
    "Top_shows['Votes']=Votes\n",
    "Top_shows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e475680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAVYA OJHA\\AppData\\Local\\Temp\\ipykernel_16836\\4097933063.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#QUES NO 10\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07df480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataste= driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "view_dataste.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "508728ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "#scraping Dataset name\n",
    "data_name= driver.find_elements(By.XPATH,\"//p[@class='normal']/b/a[1]\")\n",
    "for i in data_name:\n",
    "    if i.text is None :\n",
    "        Dataset_name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_name.append(i.text)\n",
    "\n",
    "time.sleep(4)        \n",
    "#Scraping data Type\n",
    "data_type=driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[2]/p\")\n",
    "for i in data_type[1:]:\n",
    "    if i.text is None :\n",
    "        Data_type.append(\"--\") \n",
    "    else:\n",
    "        Data_type.append(i.text)\n",
    "\n",
    "time.sleep(4) \n",
    "#Scraping Task\n",
    "task=driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[3]/p\")\n",
    "for i in task[1:]:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "        \n",
    "time.sleep(4) \n",
    "#Scraping Attribute_type\n",
    "attribute_type=driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[4]/p\")\n",
    "for i in attribute_type[1:]:\n",
    "    if i.text is None :\n",
    "        Attribute_type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_type.append(i.text)\n",
    "\n",
    "time.sleep(4)         \n",
    "#Scraping No_of_instances\n",
    "no_of_instances=driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[5]/p\")\n",
    "for i in no_of_instances[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_instances.append(i.text)\n",
    "\n",
    "time.sleep(4)         \n",
    "#Scraping No_of_attribute\n",
    "no_of_attribute=driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[6]/p\")\n",
    "for i in no_of_attribute[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_attribute.append(i.text)\n",
    "\n",
    "time.sleep(4) \n",
    "#Scraping Year\n",
    "year=driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[7]/p\")\n",
    "for i in year[1:]:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\") \n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "        \n",
    "data_dataset=pd.DataFrame({})\n",
    "data_dataset['Dataset_name']= Dataset_name\n",
    "data_dataset['Data_type']= Data_type\n",
    "data_dataset['Task']= Task\n",
    "data_dataset['Attribute_type']= Attribute_type\n",
    "data_dataset['No_of_instances']= No_of_instances\n",
    "data_dataset['No_of_attribute']= No_of_attribute\n",
    "data_dataset['Year']= Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7dec369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data_type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "905c843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAVYA OJHA\\AppData\\Local\\Temp\\ipykernel_16836\\1061689760.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#QUES NO 05\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://github.com/ \"\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de4e4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explore=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "Explore.click()\n",
    "\n",
    "Treading=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af3e2690",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (21) does not match length of index (25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m Treding_rep\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({})\n\u001b[0;32m     42\u001b[0m Treding_rep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRepository_title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m Repository_title\n\u001b[1;32m---> 43\u001b[0m Treding_rep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguage_used\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m Language_used\n\u001b[0;32m     44\u001b[0m Treding_rep\n",
      "File \u001b[1;32m~\\.ipython\\extensions\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.ipython\\extensions\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\.ipython\\extensions\\lib\\site-packages\\pandas\\core\\frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4535\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.ipython\\extensions\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (21) does not match length of index (25)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating emplty list \n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "#scraping Repository_title\n",
    "repository_title=driver.find_elements(By.XPATH,\"//span[@class='text-normal']\")\n",
    "for i in repository_title:\n",
    "    if i.text is None:\n",
    "        Repository_title.append('--')\n",
    "    else:\n",
    "        Repository_title.append(i.text)\n",
    "        \n",
    "#scraping Repository_description\n",
    "repository_description=driver.find_elements(By.XPATH,\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "for i in repository_description:\n",
    "    if i.text is None:\n",
    "        Repository_description.append('--')\n",
    "    else:\n",
    "        Repository_description.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Contributors_count\n",
    "contributors_count=driver.find_elements(By.XPATH,\"//div[@class='f6 color-text-secondary mt-2']/a[2]\")\n",
    "for i in contributors_count:\n",
    "    if i.text is None:\n",
    "        Contributors_count.append('--')\n",
    "    else:\n",
    "        Contributors_count.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Language_used\n",
    "language_used=driver.find_elements(By.XPATH,\"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "for i in language_used:\n",
    "    if i.text is None:\n",
    "        Language_used.append('--')\n",
    "    else:\n",
    "        Language_used.append(i.text)\n",
    "        \n",
    "Treding_rep=pd.DataFrame({})\n",
    "Treding_rep['Repository_title']= Repository_title\n",
    "Treding_rep['Language_used']= Language_used\n",
    "Treding_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e3dd583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHAVYA OJHA\\AppData\\Local\\Temp\\ipykernel_16836\\3120106868.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#QUES NO 06\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd7773af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Song_name, Artist_name, Last_week_rank, Peak_rank, Weeks_on_board]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Blank List\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "#Scraping Song_name\n",
    "song_name= driver.find_elements(By.XPATH,\"//span[@class='chart-results-list']/span[1]\")\n",
    "for i in song_name:\n",
    "    if i.text is None:\n",
    "        Song_name.append('--')\n",
    "    else:\n",
    "        Song_name.append(i.text)\n",
    "\n",
    "#Scraping Artist_name\n",
    "artist_name= driver.find_elements(By.XPATH,\"//span[@class='chart-results-list ']/span[2]\")\n",
    "for i in artist_name:\n",
    "    if i.text is None:\n",
    "        Artist_name.append('--')\n",
    "    else:\n",
    "        Artist_name.append(i.text)\n",
    "        \n",
    "#Scraping Last_week_rank\n",
    "last_week_rank= driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in last_week_rank:\n",
    "    if i.text is None:\n",
    "        Last_week_rank.append('--')\n",
    "    else:\n",
    "        Last_week_rank.append(i.text)\n",
    "        \n",
    "#Scraping Peak_rank\n",
    "peak_rank= driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak_rank:\n",
    "    if i.text is None:\n",
    "        Peak_rank.append('--')\n",
    "    else:\n",
    "        Peak_rank.append(i.text)\n",
    "        \n",
    "#Scraping Weeks_on_board\n",
    "weeks_on_board= driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in weeks_on_board:\n",
    "    if i.text is None:\n",
    "        Weeks_on_board.append('--')\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "\n",
    "Hot_Songs=pd.DataFrame({})\n",
    "Hot_Songs['Song_name']=Song_name\n",
    "Hot_Songs['Artist_name']=Artist_name\n",
    "Hot_Songs['Last_week_rank']=Last_week_rank\n",
    "Hot_Songs['Peak_rank']=Peak_rank\n",
    "Hot_Songs['Weeks_on_board']=Weeks_on_board\n",
    "\n",
    "Hot_Songs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3ba0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
